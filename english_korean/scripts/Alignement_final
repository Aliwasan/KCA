{"cells":[{"cell_type":"markdown","source":["### Installation et importation des bibliothèques nécessaires\n"],"metadata":{"id":"hq-qiqoI9oqj"},"id":"hq-qiqoI9oqj"},{"cell_type":"code","execution_count":null,"id":"d005c107","metadata":{"scrolled":true,"id":"d005c107"},"outputs":[],"source":["!pip install tensorflow\n","!pip install tensorflow-hub\n","!pip install tensorflow_text\n","!pip install spacy"]},{"cell_type":"code","execution_count":null,"id":"11eb90d8","metadata":{"id":"11eb90d8"},"outputs":[],"source":["from spacy.lang.en import English\n","from spacy.lang.ko import Korean\n","import tensorflow_hub as hub\n","import numpy as np\n","import tensorflow_text"]},{"cell_type":"markdown","source":["### Définition des fonctions"],"metadata":{"id":"_Yv9eqfe91pb"},"id":"_Yv9eqfe91pb"},{"cell_type":"code","execution_count":null,"id":"ceaa415a","metadata":{"id":"ceaa415a"},"outputs":[],"source":["def sentencize(text):\n","    \"\"\"\n","    Tokenise le texte d'entrée en phrases en utilisant le module sentencizer de spaCy.\n","\n","    Parameters:\n","    - texte (str): Le texte d'entrée à tokeniser.\n","\n","    Returns:\n","    - List[str]: Une liste de phrases extraites du texte d'entrée.\n","    \"\"\"\n","    ##text = text.replace('。', '。 ')\n","    sents = []\n","    nlp = English()\n","    nlp.add_pipe(\"sentencizer\")\n","    doc = nlp(text)\n","    for sent in doc.sents:\n","        sents.append(sent.text.replace('\\n', ' ').strip())\n","\n","    return sents"]},{"cell_type":"code","execution_count":null,"id":"2218cb9b","metadata":{"id":"2218cb9b"},"outputs":[],"source":["def align(en_sents, ko_sents):\n","    \"\"\"\n","    Aligne les phrases en anglais et coréen en utilisant Universal Sentence Encoder.\n","\n","    Parameters:\n","    - en_sents (list): Liste des phrases en anglais.\n","    - ko_sents (list): Liste des phrases en coréen.\n","\n","    Returns:\n","    - list: Liste des paires de phrases alignées.\n","    \"\"\"\n","    embed = hub.load(\"https://tfhub.dev/google/universal-sentence-encoder-multilingual/3\")\n","    en_result = embed(en_sents)\n","    ko_result = embed(ko_sents)\n","    sims = np.inner(en_result, ko_result)\n","\n","    costs = np.zeros((len(en_sents)+1, len(ko_sents)+1))\n","    pointers = np.zeros((len(en_sents)+1, len(ko_sents)+1), dtype=int)\n","\n","    for i in range(1, len(en_sents)+1):\n","        costs[i, 0] = costs[i-1, 0] + 1.\n","\n","    for j in range(1, len(ko_sents)+1):\n","        costs[0, j] = costs[0, j-1] + 1.\n","\n","    for i in range(1, len(en_sents)+1):\n","        for j in range(1, len(ko_sents)+1):\n","            choices = [\n","                (costs[i-1, j-1] + (1. - sims[i-1, j-1]), 1),\n","                (costs[i-1, j] + 1., 2),\n","                (costs[i, j-1] + 1., 3)\n","            ]\n","            best_choice = sorted(choices, key=lambda x: x[0])[0]\n","            costs[i, j], pointers[i, j] = best_choice\n","\n","    aligned = []\n","    i, j = len(en_sents), len(ko_sents)\n","    while i > 0 or j > 0:\n","        if pointers[i, j] == 1:\n","            i -= 1\n","            j -= 1\n","            aligned.append((en_sents[i], ko_sents[j]))\n","        elif pointers[i, j] == 2:\n","            i -= 1\n","            aligned.append((en_sents[i], ''))\n","        elif pointers[i, j] == 3:\n","            j -= 1\n","            aligned.append(('', ko_sents[j]))\n","\n","    aligned.reverse()\n","\n","    return aligned"]},{"cell_type":"code","execution_count":null,"id":"bd8e6caf","metadata":{"id":"bd8e6caf"},"outputs":[],"source":["def align_and_filter(en_sents, ko_sents):\n","\n","    aligned = align(en_sents, ko_sents)\n","\n","    # Filtre et garde que les paires de phrases qui ont une correspondance\n","    filtered_aligned = [(en, ko) for en, ko in aligned if en and ko]\n","\n","    return filtered_aligned"]},{"cell_type":"markdown","source":["### Importation fichiers et éexcution des fonctions"],"metadata":{"id":"BZOPRm-9FcBG"},"id":"BZOPRm-9FcBG"},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')\n","\n","# Accéder aux fichiers dans le dossier 'My Drive' de Google Drive\n","en_path = '/content/drive/My Drive/Colab Notebooks/spe_en.txt'\n","ko_path = '/content/drive/My Drive/Colab Notebooks/spe_ko.txt'"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"T3niZ_1XZZKy","executionInfo":{"status":"ok","timestamp":1704564707680,"user_tz":-60,"elapsed":1688,"user":{"displayName":"Camille CLAVIER","userId":"08908395152911270822"}},"outputId":"c5cf4350-bd83-48f1-827a-1573f81a82ca"},"id":"T3niZ_1XZZKy","execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}]},{"cell_type":"code","execution_count":null,"id":"31d5533a","metadata":{"id":"31d5533a"},"outputs":[],"source":["# Lire le contenu des fichiers\n","with open(en_path, 'r', encoding='utf-8') as file_en:\n","    en_lines = file_en.read()\n","\n","with open(ko_path, 'r', encoding='utf-8') as file_ko:\n","    ko_lines = file_ko.read()"]},{"cell_type":"code","source":["en_sents = sentencize(en_lines)\n","ko_sents = sentencize(ko_lines)\n","\n","# Alignement et filtrage des phrases\n","#aligned_and_filtered_sentences = align_and_filter(en_sents, ko_sents)"],"metadata":{"id":"vQ7cE6wuZjcJ"},"id":"vQ7cE6wuZjcJ","execution_count":null,"outputs":[]},{"cell_type":"code","source":["resultat_en_path = '/content/drive/My Drive/Colab Notebooks/spe_resultat_en.txt'\n","resultat_ko_path = '/content/drive/My Drive/Colab Notebooks/spe_resultat_ko.txt'\n","\n","# Enregistrement des résultats dans des fichiers séparés pour chaque langue\n","with open(resultat_en_path, \"w\", encoding=\"utf-8\") as file_en:\n","    with open(resultat_ko_path, \"w\", encoding=\"utf-8\") as file_ko:\n","        for en_sent, ko_sent in aligned_and_filtered_sentences:\n","            file_en.write(en_sent + \"\\n\")\n","            file_ko.write(ko_sent + \"\\n\")"],"metadata":{"id":"CHwBHTB7Zljr"},"id":"CHwBHTB7Zljr","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.6"},"colab":{"provenance":[{"file_id":"https://github.com/ml4asia/parallel-sentence-aligner/blob/main/parallel-sentence-aligner.ipynb","timestamp":1704551407611}]}},"nbformat":4,"nbformat_minor":5}